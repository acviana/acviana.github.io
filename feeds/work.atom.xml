<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Other Side of the Screen</title><link href="/" rel="alternate"></link><link href="/feeds/work.atom.xml" rel="self"></link><id>/</id><updated>2013-11-21T00:00:00-05:00</updated><entry><title>The Data are Inconclusive</title><link href="/posts/2013/11/21/the-data-are-inconclusive/" rel="alternate"></link><updated>2013-11-21T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:,2013-11-21:posts/2013/11/21/the-data-are-inconclusive/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;"Give me a point and I can draw a line. Give me two points and I can draw a curve. That's astronomy." - Anonymous Professor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ran the full pipeline the PSF data for the first time. The data are inconclusive.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/inconclusive-data.png" /&gt;&lt;/p&gt;
&lt;p&gt;Haha, oh error bars. Who hasn't made a plot just like this before? &lt;/p&gt;</summary><category term="psf"></category></entry><entry><title>The First Thousand PSFs</title><link href="/posts/2013/11/20/the-first-thousand-psfs/" rel="alternate"></link><updated>2013-11-20T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:,2013-11-20:posts/2013/11/20/the-first-thousand-psfs/</id><summary type="html">&lt;p&gt;In my last post on my PSF Project I characterized the the PSF shape using two orthogonal 1-D Guassians. Now I start to characterize images with thousands of stars in them. &lt;/p&gt;
&lt;h3&gt;Adding Some Zeros&lt;/h3&gt;
&lt;p&gt;One of the applications of this project is studying the telescope focus over time. One way to do this is to move from characterizing individual PSFs to characterizing the PSFs in an entire image and seeing how that changes over time. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; In other words we need to add some zeros to our lone star and start working our way towards our final dataset of 10 million. I decided to do this by digging into the first stellar field I could find. This happened to be &lt;code&gt;iabj01a2q_flt.fits&lt;/code&gt; an image of &lt;a href="http://en.wikipedia.org/wiki/47_Tucanae"&gt;NGC104&lt;/a&gt; which adds 3 more zeros to our star total, bringing it to roughly 1,500 stars. Here is the image, it's actually quite nice (sorry for the large file):&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/Visit01-iabj01a2q_flt.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;In case you want to play along at home, this image is in the public domain and can be found &lt;a href="http://archive.stsci.edu/cgi-bin/mastpreview?mission=hst&amp;amp;dataid=IABJ01A2Q"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;h3&gt;Plotting the PSF Fits&lt;/h3&gt;
&lt;p&gt;So I went ahead and fitted a Gaussian in both the row and column directions for all the stars in that image. Then I studied the distribution by plotting the fit parameters against each other in each slice.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/image_variable_matrix.png" /&gt;&lt;/p&gt;
&lt;p&gt;First of all, in hindsight what I wanted was a &lt;a href="https://www.google.com/webhp#q=scatter%20plot%20matrix"&gt;scatter plot matrix&lt;/a&gt; but this is exploratory work so I can go back and make that plot in the future.&lt;/p&gt;
&lt;p&gt;In terms of the actual data, we don't see anything noticeably different between the row and column slices, which is expected at this point, though there there may be directionally-dependent instrumental effects, such as the charge transfer efficiency, which may come into play later. Looking at the individual fit parameters there's not much going on with the amplitude but things get interesting when we plot the standard deviation against the mean (mu). However, the correlation we're seeing in the plot is actually a sampling effect. &lt;/p&gt;
&lt;h3&gt;Interpreting the Results&lt;/h3&gt;
&lt;p&gt;Let's start by explaining what &lt;code&gt;sigma&lt;/code&gt; and &lt;code&gt;mu&lt;/code&gt; mean in this context (it might be helpful to refer to my &lt;a href="http://acviana.github.io/posts/2013/11/18/counting-to-10-million-stars/"&gt;last post&lt;/a&gt;). First of all, &lt;code&gt;mu&lt;/code&gt;, the mean of the Gaussian fit is almost always between 4.5 and 5.5. This is by design because the algorithm that centers the PSF cutouts does a good job of picking the brightest pixel. &lt;code&gt;sigma&lt;/code&gt; then is a measure of the width of the PSF. &lt;/p&gt;
&lt;p&gt;The actual energy distribution of a star is a continuous distribution. However, detectors take discrete samples from this distribution, pretty much literally making a histogram. If you've played around with histograms much you might see where this is going. If a star happens to land exactly in the middle of a pixel (&lt;code&gt;mu&lt;/code&gt; = 5) most of the light from the PSF will land in that pixel. This will result in a narrow &lt;code&gt;sigma&lt;/code&gt;. But is the &lt;em&gt;same&lt;/em&gt; PSF lands right in the middle of two pixels (equidistant from their centers) then the same amount of flux is split between those two pixels. The total amount of flux is still the same, but the distribution is different. This distribution is less peaked, which is to say wider and with a larger &lt;code&gt;sigma&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;I think this is supported by the fact that as you move away from the middle of the central pixel (&lt;code&gt;mu&lt;/code&gt; = 5) the distribution of &lt;code&gt;sigma&lt;/code&gt; for a given mean moves up (gets wider) in an absolute sense, but not in a relative sense. Put another way, the width of you PSF increases the further the peak is from the central pixel, but the difference between a peaked and broad PSF at any given mean is about the same.&lt;/p&gt;
&lt;h3&gt;What's Next?&lt;/h3&gt;
&lt;p&gt;The next step is pretty clear, we need to use this distribution of parameters to characterize the "average" PSF shape in each image and plot that as a time series. This will almost certainly yield nothing but noise, but I'm confident that as we tease the data out such as separating each filter or different parts of the detector we'll start to see some real trends.&lt;/p&gt;
&lt;p&gt;But, this sampling effect is bothering me. If we just take a mean and standard distribution of all the &lt;code&gt;sigma&lt;/code&gt; parameters in each image those results are going to be heavily influenced by the sampling effect (I'm deliberately trying to avoid saying the &lt;code&gt;sigma&lt;/code&gt; of the &lt;code&gt;sigma&lt;/code&gt;s.). However, after looking at a sample set of plots I think this is likely characteristic of all our data. Consistency will have to suffice for now because as you'll see in my next post there are more pressing problems as we start to add zeros to our star count. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Most astronomers talk about PSF widths in terms of the full width at half maximum (&lt;a href="http://en.wikipedia.org/wiki/Full_width_at_half_maximum"&gt;FWHM&lt;/a&gt;). I'm using the standard deviation (sigma) in my work but they only differ by a coefficient; &lt;code&gt;FWHM = sigma x 2 x (2 x ln(s)) ^ (1/2)&lt;/code&gt;. Sorry about the lack of nice math symbols, I haven't played with that plugin yet.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="wfc3"></category><category term="psf"></category><category term="uvis"></category><category term="plots"></category></entry><entry><title>Counting to 10 Million Stars</title><link href="/posts/2013/11/18/counting-to-10-million-stars/" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:,2013-11-18:posts/2013/11/18/counting-to-10-million-stars/</id><summary type="html">&lt;p&gt;I've started a new project working with 10 million stellar PSFs. In my first few steps in the project I performed some model fitting and made a pretty visualization of the individual data points.&lt;/p&gt;
&lt;h3&gt;My New (Little) Big Data Project&lt;/h3&gt;
&lt;p&gt;I am starting a new project that I'm pretty excited, it's one of the reasons I decided to start this blog. about because it is pushing me more in the direction of "Big Data". Lots of people throw the term big data around with different meanings. Personally, I consider something to be Big Data when the complexity of the task is dominated by complications from the size of the data. The "task" could be anything related to the data including storage, computation, or visualization. Specifically, this project is going to push the computation and database aspects of my work into the Big Data zone.&lt;/p&gt;
&lt;p&gt;The dataset for this project is 10 million stellar &lt;a href="http://en.wikipedia.org/wiki/Point_spread_function"&gt;PSFs&lt;/a&gt; observations taken with the HST WFC3 UVIS instrument. These PSF were data mined from the total on-orbit data set of roughly 35 thousand WFC3 UVIS observations using a colleague's specialized FORTRAN code which extracted a 11x11 array centered on each PSF. This is an especially powerful method of constructing our dataset because it allows us to use any incidental PSFs observations when the target was not a star or stellar field.&lt;/p&gt;
&lt;h3&gt;Fitting 1-D Gaussian Distributions&lt;/h3&gt;
&lt;p&gt;After some initial work I was able to create a reader that takes the outputs text files from my colleague's code and transforms it into a numpy array. Next, we decided we wanted to start by characterizing the PSFs with two 1-D Gaussian fits through the center pixel, one in the row direction and another in the column.&lt;/p&gt;
&lt;p&gt;First of all, I was &lt;em&gt;shocked&lt;/em&gt; to learn, after an hour of googling and popping my head into people's offices, that the definition of a Gaussian distribution isn't tucked away somewhere in NumPy or SciPy. Thinking about it, it &lt;em&gt;guess&lt;/em&gt; makes sense because it's not clear what format your inputs and outputs should be, but I'm still a little surprised that all the tutorials I found on this subject began with defining the Gaussian distribution. Anyway, once I got past that the rest wasn't too hard. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.optimize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;curve_fit&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Definintion of the Guassian function.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_gaussian_dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Use curve fit to return a dictionary with all the model &lt;/span&gt;
&lt;span class="sd"&gt;    information.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;p0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;var_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;curve_fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coeff&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;amplitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sigma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;var_matrix&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;var_matrix&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;model_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resample_range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output_dict&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I use scipy's impressive &lt;code&gt;curve_fit&lt;/code&gt; function to perform the model fitting. The last argument &lt;code&gt;curve_fit&lt;/code&gt; takes is &lt;code&gt;p0&lt;/code&gt;, the initial guess for the fitting parameters. Fortunately, our data is very well behaved so we can easily do a good job guessing the initial parameters from the input data. Because I like to make my functions as general as possible I return all the possible information from the fit in a dictionary. For example, in the future I'll probably want to dig into the &lt;a href="http://en.wikipedia.org/wiki/Covariance_matrix"&gt;covariance matrix&lt;/a&gt; that the &lt;code&gt;curve_fit&lt;/code&gt; returns to calculate a goodness of fit estimator and I'll be able to do that with the same function. &lt;/p&gt;
&lt;h3&gt;Eye Candy&lt;/h3&gt;
&lt;p&gt;Finally, all this is all visualized in the 4-panel figure below.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/psf-4-panel-view.png" /&gt;&lt;/p&gt;
&lt;p&gt;The bottom row contains the row and column slices and the Gaussian fits with the model parameters printed in the upper corners. The upper row contains a heat map, and just for fun, a 3D wire frame for the PSF. I could make some tweaks here and there such as matching the wire frame and heat map color bars but this is already more than enough to visualize a single data point, I need to start working my way up to 10 million.&lt;/p&gt;</summary><category term="wfc3"></category><category term="psf"></category><category term="uvis"></category><category term="plots"></category><category term="code"></category></entry><entry><title>The Moving Target Pipeline</title><link href="/posts/2013/11/18/mtpipeline-ddrf/" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:,2013-11-18:posts/2013/11/18/mtpipeline-ddrf/</id><summary type="html">&lt;p&gt;A few weeks ago I was awarded an research grant to continue working on a prototype software pipeline for HST moving target (solar system) observations. The grant came from an internal source called the Director's Discretionary Research Fund (DDRF). My project, called the Moving Target Pipeline, was fully funded at $21,000 and allows me to buy back 25% of my time for one year to work on the project. Here is the proposal abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"We propose a moving target pipeline for the WFC3 and ACS instruments based our existing WFPC2 software to produce properly drizzled FITS images, dynamically scaled preview images, and predicted ephemeris positions. Such a pipeline is relevant to ongoing HST scientific observations, the Hubble Legacy Archive (HLA), and serves to lay the design groundwork for JWST’s moving target processing. We request funds to support a senior RIA for our software development activities. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Continuing from the proposal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Our WFPC2 pipeline addresses the 4 main issues that impede performing Solar System astronomy with HST archival data: (1) identifying cosmic rays, (2) drizzling, (3) scaled preview images, and (4) identifying incidental ephemeris observations."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This image gives an attractive visual of what we can already accomplish for WFPC2 data and will expand to the WFC3 and ACS cameras:&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/mtpipeline-mars-before-after.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can find the full proposal &lt;a href="https://www.dropbox.com/s/04m5rboqkkmzuvm/2013_Fall_DDRF_Proposal_No_Recs.pdf"&gt;here&lt;/a&gt;. Our project will be open source and available on GitHub. It will be an extension of our existing work on a citizen science project for WFPC2 which you can browse &lt;a href="" title="https://github.com/STScI-Citizen-Science/MTPipeline"&gt;here&lt;/a&gt;. This builds off a number of other grants and &lt;a href="http://archive.stsci.edu/prepds/planetpipeline/index.html"&gt;existing work&lt;/a&gt; in this area &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I hope that this phase of the project will be useful for planetary scientists using HST.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Full disclosure, I misspelled "activities" in the actual abstract. &lt;em&gt;facepalm&lt;/em&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Humblebrag / scavenger hunt, spot the astronaut co-investigator in the parent proposal :-)&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="mtpipeline"></category><category term="milestones"></category><category term="wfc3"></category><category term="acs"></category><category term="hst"></category><category term="jwst"></category><category term="wfpc2"></category></entry><entry><title>The Trouble with Tech Blogs</title><link href="/posts/2013/11/17/the-trouble-with-tech-blogs/" rel="alternate"></link><updated>2013-11-17T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:,2013-11-17:posts/2013/11/17/the-trouble-with-tech-blogs/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;the trouble with poetry is&lt;br /&gt;
that it encourages the writing of more poetry&lt;br /&gt;
 - Billy Collins, &lt;a href="http://www.edutopia.org/trouble-poetry"&gt;The Trouble with Poetry&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To paraphrase one of my favorite poets, the trouble with tech blogs is that they encourage the writing of more tech blogs. The Internet probably doesn't need another tech blog but I think this will be a fun way for me to both share and keep track of what I'm working on. Hopefully, some people will at least find it entertaining if not helpful.&lt;/p&gt;
&lt;p&gt;I tried to start this blog over a year ago with Octopress. I'd never worked with ruby before but I immediately feel in love with the idea of static HTML generated from Markdown. It seemed so elegant yet customizable, definitely a hacker's blogging platform. Of course I almost immediately broke the deploy step to GitHub and got pulled away to other projects. Then I stumbled across Pelican earlier this year, which is the same idea as Octopress but in Python! After several false starts I now finally have a working blog again! &lt;/p&gt;
&lt;p&gt;And so another tech blog begins!&lt;/p&gt;</summary><category term="pelican"></category></entry></feed>
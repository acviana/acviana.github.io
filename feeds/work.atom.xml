<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Other Side of the Screen</title><link href="http://acviana.github.io/" rel="alternate"></link><link href="http://acviana.github.io/feeds/work.atom.xml" rel="self"></link><id>http://acviana.github.io/</id><updated>2014-01-30T00:00:00-05:00</updated><entry><title>Fitting 2D Gaussians with agpy</title><link href="http://acviana.github.io/posts/2014/fitting-2d-gaussians-with-agpy/" rel="alternate"></link><updated>2014-01-30T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2014-01-30:posts/2014/fitting-2d-gaussians-with-agpy/</id><summary type="html">&lt;p&gt;After some &lt;a href="http://acviana.github.io/posts/2013/counting-to-10-million-stars/"&gt;initial work&lt;/a&gt; with fitting WFC3 UVIS PSFs with 1D Gaussians through the x and y axis I decided to look at 2d Guassian fitting as well. I was disappointed to find there wasn't already a canned procedure to do this in something like SciPy. But after not too much digging I decided to use &lt;a href="http://casa.colorado.edu/~ginsbura/"&gt;Adam Ginsburg's&lt;/a&gt; personal agpy library. I briefly met Adam at the &lt;a href="http://dotastronomy.com/"&gt;dotAstronomy&lt;/a&gt; conference last year in Boston. He's a contributor to &lt;a href="http://www.astropy.org/"&gt;AstroPY&lt;/a&gt;, &lt;a href="http://astroquery.readthedocs.org/en/latest/"&gt;AstroQuery&lt;/a&gt;, and &lt;a href="http://aplpy.github.io/"&gt;AplPy&lt;/a&gt; so I had a hunch I could trust his code and it's worked out great. &lt;/p&gt;
&lt;p&gt;You can clone the repo &lt;a href="https://github.com/keflavich/agpy"&gt;here&lt;/a&gt;. There are a couple of dependencies but I only satisfied the AstroPy and Numpy requirements and that was enough to run the &lt;code&gt;gaussfit&lt;/code&gt; function. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;agpy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gaussfitter&lt;/span&gt;

&lt;span class="n"&gt;mpfit&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;psf_fit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gaussfitter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gaussfit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;psf_array&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;returnmp&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                      &lt;span class="n"&gt;returnfitimage&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Using &lt;code&gt;gaussfit&lt;/code&gt; without the &lt;code&gt;returnmp&lt;/code&gt; or &lt;code&gt;returnfitimage&lt;/code&gt; parameters just returns a list with the following model parameters (in order): &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;height&lt;/li&gt;
&lt;li&gt;amplitude&lt;/li&gt;
&lt;li&gt;x&lt;/li&gt;
&lt;li&gt;y&lt;/li&gt;
&lt;li&gt;width_x&lt;/li&gt;
&lt;li&gt;width_y&lt;/li&gt;
&lt;li&gt;rotation angle. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Adding &lt;code&gt;returnfitimage=True&lt;/code&gt; will also return a NumPy array of the model with the same dimensions as the input data. Lastly, setting &lt;code&gt;returnmp=True&lt;/code&gt; will return a &lt;code&gt;mpfit&lt;/code&gt; instance, which is the class used to generate the fit. The class is defined in the &lt;code&gt;agpy.mpfit_custom&lt;/code&gt; module. The &lt;code&gt;mpfit&lt;/code&gt; instance contains two useful attributes, &lt;code&gt;mpfit.params&lt;/code&gt; which is the same list of parameters that &lt;code&gt;guassfit&lt;/code&gt; returns by default, and &lt;code&gt;mpfits.covar&lt;/code&gt; which is a 7x7 &lt;a href="http://en.wikipedia.org/wiki/Covariance_matrix"&gt;covariance matrix&lt;/a&gt; for the 7 modal parameters. &lt;/p&gt;
&lt;p&gt;It took me a little bit of work to figure out all these outputs but they were exactly waht I needed so I followed up with Adam and submitted my &lt;em&gt;first&lt;/em&gt; FOSS PR on GitHub with some documentation &lt;a href="https://github.com/keflavich/agpy/pull/2"&gt;improvements&lt;/a&gt;. It's a small contribution but still a personal milestone.&lt;/p&gt;
&lt;p&gt;Finally, I made a plot of the input data, the model, and the residual (difference) at two different scales. I'm definitely happy with this and am looking forward to digging into the covariance matrix a little more to really understand how well I'm fitting these PSFs.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/2d-gaussians.png" /&gt;&lt;/p&gt;</summary><category term="python"></category><category term="code"></category><category term="psf"></category><category term="uvis"></category><category term="wfc3"></category><category term="milestones"></category><category term="plots"></category><category term="hst"></category></entry><entry><title>Faster File Existence Testing with Sets</title><link href="http://acviana.github.io/posts/2014/faster-file-checking-with-sets/" rel="alternate"></link><updated>2014-01-19T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2014-01-19:posts/2014/faster-file-checking-with-sets/</id><summary type="html">&lt;h3&gt;It's Time to Think about Performance&lt;/h3&gt;
&lt;p&gt;Lately at work I've been thinking a lot about the performance of my code.  In the past most of my work fell into one of two performance categories: (roughly) overnight or (roughly) right now. In either case I didn't really care about performance. Either the task was going to take so long I had time to go do something else, in which case I didn't care if it took 1 hour or 10. Or it was going to be done fast enough I could immediately start iterating on the results, again in which case I didn't really care if was going to take 1 second or 10. I think this is indicative of the scientific computing mindset where you are both the programmer and the user: fast means fast enough for &lt;em&gt;you&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;But recently my datasets have been getting bigger (which is awesome) which has forced me to be more careful about my programming. I'm routinely finding my scripts out-growing both of my performance "categories" and either taking several minutes to run or several days. Both scenarios leave &lt;em&gt;me&lt;/em&gt; waiting around, which is the real problem. While I always try, to the best of my abilities, to write high-quality code my time is more scarce and expensive than CPU time. This means that I optimize my time, not the CPU's. However, when I &lt;em&gt;do&lt;/em&gt; find myself waiting around for some code to run, it's time to roll up my sleeves and find some speedups.&lt;/p&gt;
&lt;p&gt;The work I do is very I/O intensive involving lots of databases and data files. I/O is extremely &lt;a href="https://gist.github.com/hellerbarde/2843375"&gt;expensive&lt;/a&gt; in terms of latency so reducing trips to the disk can yield sizable speedups. Here's an example I found today that includes an introduction to a handy (and I would argue underutilized) Python type called sets.&lt;/p&gt;
&lt;h3&gt;The Slow Way&lt;/h3&gt;
&lt;p&gt;I was working on a project where I wanted to verify that all the files I had listed in a database actually existed in my file system &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. To do this I wrote a SQL query in SQLAlchemy to grab all the file names listed in the database. Then I looped over the the records returned by the query and used &lt;code&gt;os.path.exists&lt;/code&gt; to test the existence of each file in the file system.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;database_query&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fits_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Missing {}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fits_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There were 3,096 iterations (records) in this loop and the IPython &lt;code&gt;%%timeit&lt;/code&gt; cell magic gave the following result:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;103&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is a bit too long of a wait for me. It's long enough for me to get distracted by Facebook or maybe writing a blog post. I kid but task switching &lt;em&gt;does&lt;/em&gt; have a real &lt;a href="http://www.codinghorror.com/blog/2006/09/the-multi-tasking-myth.html"&gt;mental overhead&lt;/a&gt;. I'm not advocating optimizing every task that makes you sit around for a few minutes, but in this case the solution was trivial and applicable to lots of my projects.&lt;/p&gt;
&lt;h3&gt;The Fast Way&lt;/h3&gt;
&lt;p&gt;It occurred to me that I was making 3,096 separate trips to the disk. It's my understanding that there is some overhead for each disk read so I thought maybe it would be faster to read everything I needed at once and then work with the result in memory. To do this I used &lt;code&gt;glob&lt;/code&gt; and create a list of all the files in my file system I wanted to check my query against. This gave me all the data I wanted in memory from one SQL query and one &lt;code&gt;glob&lt;/code&gt; command. That reduced the problem to a membership testing problem and Python has a great built-in type for this, &lt;a href="http://docs.python.org/2/tutorial/datastructures.html#sets"&gt;sets&lt;/a&gt;. Sets are unordered &lt;a href="https://en.wikipedia.org/wiki/Hash_table"&gt;hash tables&lt;/a&gt; which means their average performance for a lookup operation is the holy grail of speed, &lt;code&gt;O(1)&lt;/code&gt;. Incorporating all this into my code looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt;
&lt;span class="n"&gt;file_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;glob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glob&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_search_string&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;database_query&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fits_file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;file_set&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Missing {}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fits_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It turns out I was right, this is almost a full order of magnitude faster than my original code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;best&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;10.6&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Caveats&lt;/h3&gt;
&lt;p&gt;So I think the principles behind this speed up are solid but, as always, your mileage my vary and there are some caveats I can think of.&lt;/p&gt;
&lt;p&gt;First of all, the file system I am searching is a network file system that I'm connecting to over VPN, this makes each disk read exceptionally expensive. Secondly, the &lt;code&gt;glob&lt;/code&gt; operation is very expensive, almost all the run time is spent in that step. So if you're only checking a few files it might be faster to just look them up one-by-one than to use wildcards to scan a file tree. I'm not sure where the tipping point is, but it's certainly worthwhile if you're checking every file like I am.&lt;/p&gt;
&lt;p&gt;I've just starting thinking about these topics so if I missed something in my code or my explanation I would love to hear about it the comments.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you're wondering why I want to do this, yes, it's because I screwed up and put the wrong files in the database.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="python"></category><category term="code"></category></entry><entry><title>2014 Summer Internship Opportunity</title><link href="http://acviana.github.io/posts/2014/2014-summer-internship-opportunity/" rel="alternate"></link><updated>2014-01-16T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2014-01-16:posts/2014/2014-summer-internship-opportunity/</id><summary type="html">&lt;p&gt;The Moving Target Pipeline group at the Space Telescope Science Institute (STScI) in Baltimore, Maryland seeks a graduate or undergraduate student for a paid summer internship through the Institute's Space Astronomy Summer Program (SASP). The intern will work with our group to develop, test, and run our software pipeline which processes Solar System object observations ("moving targets") taken with the Hubble Space Telescope.&lt;/p&gt;
&lt;p&gt;The Moving Target Pipeline is the first attempt in the 22-year history of the Hubble Space Telescope to create a generalized data processing pipeline to meet the unique requirements of Solar System data. Using Python and MySQL the pipeline creates calibrated science data, dynamically scaled preview images, and predicts possible detections of "incidental" or serendipitous objects such as moons and asteroids. These data products and software techniques are of broad interest to the solar system research community as well as STScI, even influencing plans for the new James Webb Space Telescope (JWST). More information on the project can be found &lt;a href="http://acviana.github.io/posts/2013/mtpipeline-ddrf/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is an ideal opportunity for a student interested in software development, whose goal is either a career in software or wishes to add programming to his or her highly-desirable skill set. Our intern will be exposed to many aspects of professional software development including documentation, testing, code reviews, distributed version control, and remote software execution. Last year's intern in our group (a college senior) reported the internship experience helpful in both job interviews and subsequently, on the job.&lt;/p&gt;
&lt;p&gt;Strong candidates for this position will have experience in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Working in the Linux command line  &lt;/li&gt;
&lt;li&gt;The Python programming language  &lt;/li&gt;
&lt;li&gt;SQL databases, specifically MySQL  &lt;/li&gt;
&lt;li&gt;Version control, specifically Git and GitHub  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A demonstrated ability to work and learn independently as well as attention to detail are all valued. A background in astronomy or physics is desirable but not required. Applicants with other relevant qualifications, such as experience in other programming languages or success in prior internships, are encouraged to demonstrate how they could contribute to our work.&lt;/p&gt;
&lt;p&gt;Candidates are invited apply by follow this &lt;a href="http://www.stsci.edu/institute/smo/students/applications"&gt;link&lt;/a&gt;. Women and minorities are especially encouraged to apply. The deadline for applications is January 31st, 2014.&lt;/p&gt;
&lt;p&gt;Please note that all applications go into a general applicant pool and will be considered for &lt;em&gt;all&lt;/em&gt;  internship opportunities available through the SASP. If you are specifically interested in an internship with our Moving Target project please include the words "Moving Target" somewhere in your application to ensure our group reviews your application.&lt;/p&gt;
&lt;p&gt;We look forward to your application,&lt;/p&gt;
&lt;p&gt;The Moving Target Team&lt;br /&gt;
Space Telescope Science Institute&lt;br /&gt;
Baltimore, Maryland   &lt;/p&gt;</summary><category term="mtpipeline"></category></entry><entry><title>Guilty As Charged</title><link href="http://acviana.github.io/posts/2013/guilty-as-charged/" rel="alternate"></link><updated>2013-12-19T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-12-19:posts/2013/guilty-as-charged/</id><summary type="html">&lt;p&gt;Earlier this month the wonderful Randall Munroe at XKCD posted this great &lt;a href="http://xkcd.com/1296/"&gt;strip&lt;/a&gt; poking fun at the decrease in commit message quality as a project ages.  &lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="http://imgs.xkcd.com/comics/git_commit.png/"&gt;&lt;/p&gt;
&lt;p&gt;As the meme goes, "nailed it".&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/github-commit-history.png"&gt;&lt;/p&gt;
&lt;p&gt;(I did finally get everything to work BTW.)&lt;/p&gt;</summary><category term="git"></category><category term="humor"></category></entry><entry><title>That Time I Made a Metaclass</title><link href="http://acviana.github.io/posts/2013/that-time-i-made-a-metaclass/" rel="alternate"></link><updated>2013-12-04T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-12-04:posts/2013/that-time-i-made-a-metaclass/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;"If you don't know what a metaclass is you don't need to use one."&lt;br /&gt;
- David Beazley&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was shooting some messages back and forth this morning with some current and former coworkers on Twitter on the topic of Python Metaclasses. One coworker said metaclasses was something he'd never really got around to using. I mentioned that I had used them exactly once to generate database Object Relational Models (ORMs). My second coworker said that was a common use case and that it would be nice to see an example. Since a tech blog is a shining example of a hammer searching for a nail I immediately got to work on this post.&lt;/p&gt;
&lt;h3&gt;Some Background&lt;/h3&gt;
&lt;p&gt;I took David Beazley's Python Master class in 2009 (?) and I still remembered the quote from the start of this post, so for years I didn't worry about metaclasses because I knew I didn't need them. Finally though, I did need them.&lt;/p&gt;
&lt;p&gt;One of my favorite Python modules, despite its near vertical learning curve, is the &lt;a href="http://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt; database toolkit. One of the features in this module is a very nice Object Relational Mapper (ORM) which maps database tables to Python classes. The ORM can be used in a number of ways and I prefer to use what's called the &lt;a href="http://docs.sqlalchemy.org/en/rel_0_9/orm/extensions/declarative.html"&gt;Declarative Base&lt;/a&gt; syntax. The basic idea is that you create a parent class called &lt;code&gt;Base&lt;/code&gt; that contains information about your database connection and metadata. All your ORM classes are then child classes of &lt;code&gt;Base&lt;/code&gt; and you use them to work with your tables. Here is a basic example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MyTable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Defines a SQLAlchemy ORM&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_dict&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__dict__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;__tablename__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;my_table&amp;#39;&lt;/span&gt;
    &lt;span class="nb"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;primary_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;foo1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;foo2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;foo3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You could imagine an application that would need to dynamically define several of these tables, but you don't have to because I'm about to tell you about one. &lt;/p&gt;
&lt;h3&gt;My Problem&lt;/h3&gt;
&lt;p&gt;The most common image file format in astronomy is called &lt;a href="http://en.wikipedia.org/wiki/FITS"&gt;FITS&lt;/a&gt;. FITS files have multiple layers (called "extensions") each with it's own set of metadata (called "headers"). For one of my projects we have over a million FITS files and we index these files with a MySQL database that maps the header keywords in the extensions to fields in SQL tables. We have about a dozen different file types, each with a handful of extensions, and each of those has 10s of header keywords. If you spelled out every ORM explicitly with a class and an attribute for every column like we do above we would literally have thousands of rows of ORM definitions. I'm a big proponent of the DRY principle (Don't Repeat Yourself) for the sake of readability and maintainability so this was a pretty big red flag in my opinion. &lt;/p&gt;
&lt;h3&gt;My Solution&lt;/h3&gt;
&lt;p&gt;Notice that we don't need to dynamically create many instances of the same class. Instead we need to dynamically create many class definitions. This is the specific need the drove me to use a metaclass.I ended up with something like the code snippet below. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;orm_factory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;class_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Creates SQLA ORM Classes.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;init_dict&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__dict__&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;init_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;class_attributes_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="n"&gt;class_attributes_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;__init__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;__init__&lt;/span&gt;
    &lt;span class="n"&gt;class_attributes_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;id&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;primary_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;class_attributes_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;__tablename__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;class_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lower&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;
    &lt;span class="n"&gt;class_attributes_dict&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__update__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_column_defs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;class_name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;class_name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Base&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="n"&gt;class_attributes_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You could then call &lt;code&gt;orm_factory&lt;/code&gt; like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Class1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orm_factory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Class1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Class2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orm_factory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Class2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Class3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orm_factory&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Class3&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And there you have your classes, dynamically created using metaclasses.&lt;/p&gt;
&lt;h3&gt;Solution Breakdown&lt;/h3&gt;
&lt;p&gt;Let's walk through this. First, let's look at the last line for the &lt;code&gt;orm_factory&lt;/code&gt; function. This is maybe the "craziest" part of the whole function. That's because &lt;code&gt;type&lt;/code&gt; is actually a metaclass constructor. That's right, the thing that tells you &lt;code&gt;type(1)&lt;/code&gt; is &lt;code&gt;int&lt;/code&gt; is also used as a metaclass constructor to maintain backward comparability &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. (If you want to tickle your brain check the type of type). To really wrap your head around metaclasses and type check out Jake VanderPlas's &lt;a href="http://jakevdp.github.io/blog/2012/12/01/a-primer-on-python-metaclasses/"&gt;excellent post&lt;/a&gt; on the subject. &lt;/p&gt;
&lt;p&gt;The basic idea is you pass &lt;code&gt;type&lt;/code&gt; the string name you would to give the constructed class, a tuple of parent classes, and a dictionary of any other attributes for the class. Looking up the code block you'll see that I create a dictionary for these attributes called &lt;code&gt;class_attribute_dict&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Notice I'm doing a little bit of magic by creating a &lt;code&gt;get_column_defs()&lt;/code&gt; function. This function will dynamically add the appropriate column definitions, for example by pulling them from the FITS headers. The implementation of this function isn't import to the topic of this post, what matters is that these is some dynamic aspect to the column definition (and hence the class creation) that necessitates the use of a metaclass. &lt;/p&gt;
&lt;p&gt;Also, notice that the attributes in  &lt;code&gt;class_attribute_dict&lt;/code&gt; includes an &lt;code&gt;__init__&lt;/code&gt; method defined as a function. This is one of those weird moments in python when you define a function &lt;em&gt;inside&lt;/em&gt; of another function. We do this because we're never going to use the &lt;code&gt;__init__&lt;/code&gt; function outside of the &lt;code&gt;orm_factory&lt;/code&gt; function it's nested in so there is no reason to globally scope it. In this case we define &lt;code&gt;__init__&lt;/code&gt; just like it was a method with a reference to &lt;code&gt;self&lt;/code&gt; and everything. Even though there is nothing special about this function it will still take on the properties of a method after it's passed to type. I personally think is pretty cool and give you some insight into how classes are built.&lt;/p&gt;
&lt;p&gt;So that's my example of metaclasses. It took me a couple of long days to figure this all out but I learned a lot about the inner workings of Python in the process. It's not so hard once you see it, but it's also not something I anticipate having to do again soon.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;I swear I read this somewhere but I'm still hunting for the source.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="code"></category><category term="python"></category><category term="database"></category></entry><entry><title>The Joy of "Screen"</title><link href="http://acviana.github.io/posts/2013/the-joy-of-screen/" rel="alternate"></link><updated>2013-11-24T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-24:posts/2013/the-joy-of-screen/</id><summary type="html">&lt;p&gt;Because I frequently work remotely as well as run long processes I recently gave up my desktop system at work in exchange for a laptop and a couple of virtual machines. I use the laptop for day-to-day work but offload longer computations or automated processes to my VMs. But before I could fully take advantage of this setup  I had to solve a new problem I didn't have to worry about with my desktop, how do I run a process remotely without maintaining an open SSH connection? &lt;/p&gt;
&lt;p&gt;I went to our IT department with this question and my favorite sys admin&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; turned me onto the joy of &lt;a href="http://en.wikipedia.org/wiki/GNU_Screen"&gt;Screen&lt;/a&gt;. Since then I've been spreading the word around my branch about this awesome little tool. Screen is a robust little piece of software that allows you to manage your shell session in a variety of ways. Screen can do a lot and it's worth taking the time to read through some tutorials but I'll explain my basic workflow in this post to start a process on a remote host and leave it running after closing the SSH connection. &lt;/p&gt;
&lt;p&gt;First you SSH into you remote machine as normal and then type&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;screen&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ls&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is going to return a list of all the Screen&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; sessions you have active on your machine. If this is your first time using screen you should see something like &lt;code&gt;No Sockets found in ...&lt;/code&gt;. Great, now we're going to start up our first Screen session, I'm going to call this one &lt;code&gt;making_science&lt;/code&gt;, so then I type:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;screen&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;S&lt;/span&gt; &lt;span class="n"&gt;making_science&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then you'll get a new command line prompt, you are now "in" your Screen session, or as Screen calls it "attached". If you run &lt;code&gt;screen -ls&lt;/code&gt; again you'll now get something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;there&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;screen&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="mf"&gt;48625.&lt;/span&gt;&lt;span class="n"&gt;making_science&lt;/span&gt;    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Attached&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;Socket&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;blah&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;blah&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now go ahead and launch your long script, I usually run it in the background by appending script with an ampersand (&lt;code&gt;&amp;amp;&lt;/code&gt;) like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="err"&gt;$&lt;/span&gt; &lt;span class="n"&gt;make_some_science&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And now we finally get to the good part, we're going to detach the session without killing the process, even if you close the SSH connection. You can do this either by typing &lt;code&gt;ctrl + a&lt;/code&gt; then &lt;code&gt;:detach&lt;/code&gt;,  or if you don't have those key bindings, &lt;code&gt;screen -D&lt;/code&gt;. Anytime you want to check back in one it just reattach your screen session on the same host with &lt;code&gt;screen -r&lt;/code&gt; and everything will be just as you left it, even your command history. When you're finally done with your session you can just kill it with &lt;code&gt;exit&lt;/code&gt; and it'll be removed from your list of screens.&lt;/p&gt;
&lt;p&gt;Lastly, if like me you're suspicious by nature, you're going to want to check to make sure your process is &lt;em&gt;actualy&lt;/em&gt; still running so you don't die a little inside when you come back to work the next morning expecting a pile of fresh data and instead get a stack trace. There are a variety of tools that allow you to do this, the two command line solutions I use are &lt;code&gt;top&lt;/code&gt; &lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; and &lt;code&gt;ps&lt;/code&gt;. Either one will list the processed currently running on your machine. I usually start up a process with screen, detach the session, confirm that the process is still running with &lt;code&gt;top&lt;/code&gt; or &lt;code&gt;ps&lt;/code&gt; and &lt;em&gt;then&lt;/em&gt; close the SSH connection. If I'm feeling extra careful I'll check the log files from another host after closing th SSH to make sure things are still humming along. &lt;/p&gt;
&lt;p&gt;And that's it. Go ask your IT department very nicely if they can build you a VM and then unleash your codebase while you go about your life. Horray! &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you're going to do any serious DevOps work make friends with you IT staff. Ask them for help nicely and thank them profusely. Buy them beers. A good relationship with your sys admins in invaluable to getting sh*t done. This really shouldn't even be a footnote.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Screen is inconsistently capitalized in the websites and blogs I saw. I decided to follow the convention in the GNU &lt;a href="https://www.gnu.org/software/screen/"&gt;docs&lt;/a&gt; and treat it as a proper noun. I bring this up here because this is the first place in this post where Screen isn't capitalized because it starts a sentence. I also bring it up because I'm a nerd.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Depending on your version of &lt;code&gt;top&lt;/code&gt; you can type &lt;code&gt;u&lt;/code&gt; on the main screen and then your username to view all the processes being run by your user name. Given that &lt;code&gt;top&lt;/code&gt; shows all the system processes this helps remove all the ones you don't care about.&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="devops"></category></entry><entry><title>A Basic Automation Setup for Astronomy: Part 1</title><link href="http://acviana.github.io/posts/2013/a-basic-automation-setup/" rel="alternate"></link><updated>2013-11-23T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-23:posts/2013/a-basic-automation-setup/</id><summary type="html">&lt;p&gt;For one of my projects at work I engineered an automation platform for one of our instrument teams. This platform allows us to automatically execute 20+ daily scripts, written in a variety of programming languages, as data is coming down from the telescope. All the scripts for our team, from the downloading the data, copying and indexing the data in an SQL database, running in-house scripts, and system self-diagnostics run on the same automation platform. Adding a script to this platform requires as little as 4 lines of code. Our codebase is updated with hourly builds from our team of 6 developers and all execution and maintenance is performed via a service account on a Linux Red Hat virtual machine.&lt;/p&gt;
&lt;p&gt;This is going to be a series of posts where I'm going to cover all the odds and ends I had to stick together to build this system. This is far from a generalized solution but hopefully you can learn from my mistakes and build something to suit your own needs faster and better than I did.&lt;/p&gt;
&lt;p&gt;As an aside, this is what I consider to be the DevOps side of my job. It's only in the last year that this has become part of my work and it's only now that I'm starting to identify this as a valuable skill in response to a hard problem. Previously, I was just embarrassed I kept breaking things. But looking back on it, automating this system in this way is one of the hardest things I've done in my job. I'm fortunate I have a team that didn't tell me to stop wasting my time and do it the old way by running everything by hand. And now that it's up and running I haven't had to fix it in weeks.&lt;/p&gt;
&lt;p&gt;In this first post we'll just cover combining the automated execution solution (cron) with the environment configuration solution (Ureka).&lt;/p&gt;
&lt;h3&gt;Cron: Running Your Code&lt;/h3&gt;
&lt;p&gt;At the heart of our system, like many automation solutions, is the Unix job scheduler &lt;a href="http://en.wikipedia.org/wiki/Cron"&gt;cron&lt;/a&gt;. There are other applications our team considered using to fill this role such as &lt;a href="http://research.cs.wisc.edu/htcondor/"&gt;Condor&lt;/a&gt; a distributed computing platform, &lt;a href="http://jenkins-ci.org/"&gt;Jenkins CI&lt;/a&gt; a java-based web frontend for continuous integration, &lt;a href="http://en.wikipedia.org/wiki/Launchd"&gt;launchd&lt;/a&gt; an OSX job scheduler, and even &lt;a href="http://www.celeryproject.org/"&gt;Celery&lt;/a&gt; a distributed job queue. In the end we chose cron because, once we got it working, it was the most direct and simple solution for our architecture. However, as you'll see later, that simplicity made it incredibly difficult to use with IRAF/PyRAF. But first let's start with some cron basics.&lt;/p&gt;
&lt;p&gt;If you look at some cron tutorials you'll see that cron jobs are scheduled with a syntax like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will execute &lt;code&gt;my_script.py&lt;/code&gt; every day at 11 am. This is nothing you can't find in any cron tutorial but here are some tricks I found useful that I had to dig around for a little bit. You can also run multiple scripts sequentially on one line by separating them with a semicolon (&lt;code&gt;;&lt;/code&gt;) like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Each script will run once after the preceding script finishes regardless of the preceding script's exit status. Alternatively, you can make the execution of the second script dependent on the successful completion of the first script with a double ampersand (&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;) like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now cron is likely going to try to be helpful by emailing you any outputs from your code. The recipient of this email can be defined by setting the &lt;code&gt;MAILTO&lt;/code&gt; variable before the job definitions like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;MAILTO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;my_team_list&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;my_institution&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edu&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also define any other variables or alias you want in this same manner. But let's say that you only want to hear from cron when something breaks. You can do this by redirecting &lt;code&gt;STDOUT&lt;/code&gt; just as you would from the command line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;MAILTO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;my_team_list&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;my_institution&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edu&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you will only get an email when something gets passed to &lt;code&gt;STDERR&lt;/code&gt;. For our setup, this is all the cron syntax we needed to understand. Now onto setting up you environment.&lt;/p&gt;
&lt;h3&gt;Ureka: Setting Up Your Environment&lt;/h3&gt;
&lt;p&gt;Right now you might be thinking, &lt;em&gt;"My environment is already set up! Right?"&lt;/em&gt;. This is when using cron starts to become a little non-trivial; cron does not know about your &lt;a href="http://stackoverflow.com/questions/2229825/where-can-i-set-environment-variables-that-crontab-will-use"&gt;enviorment variables&lt;/a&gt;, like &lt;em&gt;any&lt;/em&gt; of them. In a lot of applications this is not a big deal, you can just define some environment variables just like I defined &lt;code&gt;MAILTO&lt;/code&gt; above, and you're set. &lt;/p&gt;
&lt;p&gt;But, if you're in astronomy one of your default software tools is likely IRAF/PyRAF. This takes installing software and declaring environment variables to an entirely new level of difficulty. I spent &lt;em&gt;weeks&lt;/em&gt; working on the problem of getting cron to run in an IRAF/PyRAF compatible environment without any success. I tried half a dozen different approaches and talked to several people, all of who confessed to giving up due to the same complication. In the end, I partnered with one of our best IT people and we came up with a solution. The first step of that solution is to use Ureka. &lt;/p&gt;
&lt;p&gt;&lt;a href="http://ssb.stsci.edu/ureka/"&gt;Ureka&lt;/a&gt; is a software package developed by STScI and Gemini. From the website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ureka is a collection of useful astronomy software that is generally centered around Python and IRAF. The software provides everything you need to run the data reduction packages provided by STScI and Gemini.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ureka is great, it builds a completely isolated IRAF and Python environment in minutes and loads or unloads the environment with a single command. You can run ds9, IRAF, PyRAF, and Python. Plus Python comes loaded with IPython, the IPython notebook, matplotlib, numpy, scipy, and pandas. If you need more than that you can immediately run &lt;code&gt;pip install&lt;/code&gt; because your paths have already been set up for you. You're on your own for IDL though.&lt;/p&gt;
&lt;p&gt;Whether you're like me and work on an institute machine with pre-built libraries or if you're running everything on your own machine and have root, Ureka is worth looking into because it &lt;em&gt;just works&lt;/em&gt;. I spent a lot of time learning to use package managers, building from source into different prefixes, virtualenv, and the ins and outs of pip, but when I got a new virtual machine last month I used Ureka and literally set up everything I needed in 3 commands. I was sold.&lt;/p&gt;
&lt;p&gt;So now we have our automation tool, cron, and our environment setup with Ureka. Now it's time to combine them.&lt;/p&gt;
&lt;h3&gt;Cron + Ureka: Automatic Environment Setup&lt;/h3&gt;
&lt;p&gt;Like we just saw, you can run more than one script on a single line in cron. You can start the Ureka environment with the command &lt;code&gt;ur_setup&lt;/code&gt; and exit with &lt;code&gt;ur_forget&lt;/code&gt;. So I &lt;em&gt;thought&lt;/em&gt; the following command would have been enough to run our scripts:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;ur_setup&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But it doesn't work. Somehow this does not run &lt;code&gt;my_second_script.py&lt;/code&gt; using the environment set up by &lt;code&gt;ur_setup&lt;/code&gt;, my guess is that each script is launched in an independent shell that doesn't propagate variables back to the parent cron environment. This independence is generally a desirable feature so that makes sense, though it makes life hard in our case. This is where everyone I talked to crashed and burned when trying to use cron to automate astronomy software, whether they were using Ureka or not. But eventually one of our IT specialists worked out a wrapper script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/tcsh&lt;/span&gt;
ur_setup
&lt;span class="s2"&gt;&amp;quot;$*&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's non-intuitive at first but what it does it runs &lt;code&gt;ur_setup&lt;/code&gt; and then takes a script name as a command line argument and runs that script. Because this is all done in the same shell session the script is launched in the Ureka environment - &lt;em&gt;finally&lt;/em&gt;. I can't tell you how happy I was to finally get this to work. The execution looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;cron_setup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Done, Right?&lt;/h3&gt;
&lt;p&gt;That was a bit of a long post, and you might be tempted to call it quits and just run with this setup, but I would encourage you not to. We still have to talk about a deployment solution for your code using your version control system (because your code is version controlled right?), using Python to wrap code written in other languages, using the Python logging module to generate logs. Doesn't that sound nice? I'll put the link to all that right [here] once it's ready.&lt;/p&gt;</summary><category term="code"></category><category term="devops"></category></entry><entry><title>The Data are Inconclusive</title><link href="http://acviana.github.io/posts/2013/the-data-are-inconclusive/" rel="alternate"></link><updated>2013-11-21T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-21:posts/2013/the-data-are-inconclusive/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;"Give me a point and I can draw a line. Give me two points and I can draw a curve. That's astronomy." - Anonymous Professor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ran the full pipeline the PSF data for the first time. The data are inconclusive.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/inconclusive-data.png" /&gt;&lt;/p&gt;
&lt;p&gt;Haha, oh error bars. Who hasn't made a plot just like this before? &lt;/p&gt;</summary><category term="psf"></category></entry><entry><title>The First Thousand PSFs</title><link href="http://acviana.github.io/posts/2013/the-first-thousand-psfs/" rel="alternate"></link><updated>2013-11-20T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-20:posts/2013/the-first-thousand-psfs/</id><summary type="html">&lt;p&gt;In my last post on my PSF Project I characterized the PSF shape by fitting a 1-D Gaussian to the a row and column slice through the central pixel. In this post I start to think about how to characterize entire images with thousands of stars.&lt;/p&gt;
&lt;h3&gt;Adding Some Zeros&lt;/h3&gt;
&lt;p&gt;Many applications for the PSF database involve looking at PSF changes over a time series. One way to do this is to move from characterizing individual PSFs to characterizing the PSFs in an entire image and seeing how that changes over time. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; In other words, we need to add some zeros to our lone star and start working our way towards our final dataset of 10 million. I decided to do this by digging into the first stellar field I could find. This happened to be &lt;code&gt;iabj01a2q_flt.fits&lt;/code&gt; an image of &lt;a href="http://en.wikipedia.org/wiki/47_Tucanae"&gt;NGC104&lt;/a&gt; which adds 3 more zeros to our star total, bringing it to roughly 1,500 stars. Here is the image, it's actually quite nice (sorry for the large file):&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/Visit01-iabj01a2q_flt.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;In case you want to play along at home, this image is in the public domain and can be found &lt;a href="http://archive.stsci.edu/cgi-bin/mastpreview?mission=hst&amp;amp;dataid=IABJ01A2Q"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;h3&gt;Plotting the PSF Fits&lt;/h3&gt;
&lt;p&gt;So I went ahead and fitted a Gaussian in both the row and column directions for all the stars in that image. Then I studied the distribution by plotting the fit parameters against each other in each slice.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/image_variable_matrix.png" /&gt;&lt;/p&gt;
&lt;p&gt;First of all, in hindsight what I wanted was a &lt;a href="https://www.google.com/webhp#q=scatter%20plot%20matrix"&gt;scatter plot matrix&lt;/a&gt; but this is exploratory work so I can go back and make that plot in the future.&lt;/p&gt;
&lt;p&gt;In terms of the actual data, we don't see anything noticeably different between the row and column slices, which is expected at this point, though there there may be directionally-dependent instrumental effects, such as the charge transfer efficiency, which may come into play later. Looking at the individual fit parameters there's not much going on with the amplitude but things get interesting when we plot the standard deviation against the mean (&lt;code&gt;mu&lt;/code&gt;). However, the correlation we're seeing in the plot is actually a sampling effect. &lt;/p&gt;
&lt;h3&gt;Interpreting the Results&lt;/h3&gt;
&lt;p&gt;Let's start by explaining what &lt;code&gt;sigma&lt;/code&gt; and &lt;code&gt;mu&lt;/code&gt; mean in this context (it might be helpful to refer to my &lt;a href="http://acviana.github.io/posts/2013/11/18/counting-to-10-million-stars/"&gt;last post&lt;/a&gt;). First of all, &lt;code&gt;mu&lt;/code&gt;, the mean of the Gaussian fit is almost always between 4.5 and 5.5. This is by design because the algorithm that centers the PSF cutouts does a good job of picking the brightest pixel. &lt;code&gt;sigma&lt;/code&gt; then is a measure of the width of the PSF. &lt;/p&gt;
&lt;p&gt;The actual energy distribution of a star is a continuous distribution. However, detectors take discrete samples from this distribution, pretty much literally making a histogram. If you've played around with histograms much you might see where this is going. If a star happens to land exactly in the middle of a pixel (&lt;code&gt;mu&lt;/code&gt; = 5) most of the light from the PSF will land in that pixel. This will result in a narrow &lt;code&gt;sigma&lt;/code&gt;. But is the &lt;em&gt;same&lt;/em&gt; PSF lands right in the middle of two pixels (equidistant from their centers) then the same amount of flux is split between those two pixels. The total amount of flux is still the same, but the distribution is different. This distribution is less peaked, which is to say wider and with a larger &lt;code&gt;sigma&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;I think this is supported by the fact that as you move away from the middle of the central pixel (&lt;code&gt;mu&lt;/code&gt; = 5) the distribution of &lt;code&gt;sigma&lt;/code&gt; for a given mean moves up (gets wider) in an absolute sense, but not in a relative sense. Put another way, the width of you PSF increases the further the peak is from the central pixel, but the difference between a peaked and broad PSF at any given mean is about the same.&lt;/p&gt;
&lt;h3&gt;What's Next?&lt;/h3&gt;
&lt;p&gt;The next step is pretty clear, we need to use this distribution of parameters to characterize the "average" PSF shape in each image and plot that as a time series. This will almost certainly yield nothing but noise, but I'm confident that as we tease the data out such as separating each filter or different parts of the detector we'll start to see some real trends.&lt;/p&gt;
&lt;p&gt;But, this sampling effect is bothering me. If we just take a mean and standard distribution of all the &lt;code&gt;sigma&lt;/code&gt; parameters in each image those results are going to be heavily influenced by the sampling effect (I'm deliberately trying to avoid saying the &lt;code&gt;sigma&lt;/code&gt; of the &lt;code&gt;sigma&lt;/code&gt;s.). However, after looking at a sample set of plots I think this is likely characteristic of all our data. Consistency will have to suffice for now because as you'll see in my next post there are more pressing problems as we start to add zeros to our star count. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Most astronomers talk about PSF widths in terms of the full width at half maximum (&lt;a href="http://en.wikipedia.org/wiki/Full_width_at_half_maximum"&gt;FWHM&lt;/a&gt;). I'm using the standard deviation (sigma) in my work but they only differ by a coefficient; &lt;code&gt;FWHM = sigma x 2 x (2 x ln(s)) ^ (1/2)&lt;/code&gt;. Sorry about the lack of nice math symbols, I haven't played with that plugin yet.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="wfc3"></category><category term="psf"></category><category term="uvis"></category><category term="plots"></category></entry><entry><title>Counting to 10 Million Stars</title><link href="http://acviana.github.io/posts/2013/counting-to-10-million-stars/" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-18:posts/2013/counting-to-10-million-stars/</id><summary type="html">&lt;p&gt;I've started a new project working with 10 million stellar PSFs. In my first few steps in the project I performed some model fitting and made a pretty visualization of the individual data points.&lt;/p&gt;
&lt;h3&gt;My New (Little) Big Data Project&lt;/h3&gt;
&lt;p&gt;I am starting a new project that I'm pretty excited, it's one of the reasons I decided to start this blog. about because it is pushing me more in the direction of "Big Data". Lots of people throw the term big data around with different meanings. Personally, I consider something to be Big Data when the complexity of the task is dominated by complications from the size of the data. The "task" could be anything related to the data including storage, computation, or visualization. Specifically, this project is going to push the computation and database aspects of my work into the Big Data zone.&lt;/p&gt;
&lt;p&gt;The dataset for this project is 10 million stellar &lt;a href="http://en.wikipedia.org/wiki/Point_spread_function"&gt;PSFs&lt;/a&gt; observations taken with the HST WFC3 UVIS instrument. These PSF were data mined from the total on-orbit data set of roughly 35 thousand WFC3 UVIS observations using a colleague's specialized FORTRAN code which extracted a 11x11 array centered on each PSF. This is an especially powerful method of constructing our dataset because it allows us to use any incidental PSFs observations when the target was not a star or stellar field.&lt;/p&gt;
&lt;h3&gt;Fitting 1-D Gaussian Distributions&lt;/h3&gt;
&lt;p&gt;After some initial work I was able to create a reader that takes the outputs text files from my colleague's code and transforms it into a numpy array. Next, we decided we wanted to start by characterizing the PSFs with two 1-D Gaussian fits through the center pixel, one in the row direction and another in the column.&lt;/p&gt;
&lt;p&gt;First of all, I was &lt;em&gt;shocked&lt;/em&gt; to learn, after an hour of googling and popping my head into people's offices, that the definition of a Gaussian distribution isn't tucked away somewhere in NumPy or SciPy. Thinking about it, it &lt;em&gt;guess&lt;/em&gt; makes sense because it's not clear what format your inputs and outputs should be, but I'm still a little surprised that all the tutorials I found on this subject began with defining the Gaussian distribution. Anyway, once I got past that the rest wasn't too hard. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.optimize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;curve_fit&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Definintion of the Guassian function.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_gaussian_dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Use curve fit to return a dictionary with all the model &lt;/span&gt;
&lt;span class="sd"&gt;    information.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;p0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;var_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;curve_fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coeff&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;amplitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sigma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;var_matrix&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;var_matrix&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;model_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resample_range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output_dict&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I use scipy's impressive &lt;code&gt;curve_fit&lt;/code&gt; function to perform the model fitting. The last argument &lt;code&gt;curve_fit&lt;/code&gt; takes is &lt;code&gt;p0&lt;/code&gt;, the initial guess for the fitting parameters. Fortunately, our data is very well behaved so we can easily do a good job guessing the initial parameters from the input data. Because I like to make my functions as general as possible I return all the possible information from the fit in a dictionary. For example, in the future I'll probably want to dig into the &lt;a href="http://en.wikipedia.org/wiki/Covariance_matrix"&gt;covariance matrix&lt;/a&gt; that the &lt;code&gt;curve_fit&lt;/code&gt; returns to calculate a goodness of fit estimator and I'll be able to do that with the same function. &lt;/p&gt;
&lt;h3&gt;Eye Candy&lt;/h3&gt;
&lt;p&gt;Finally, all this is all visualized in the 4-panel figure below.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/psf-4-panel-view.png" /&gt;&lt;/p&gt;
&lt;p&gt;The bottom row contains the row and column slices and the Gaussian fits with the model parameters printed in the upper corners. The upper row contains a heat map, and just for fun, a 3D wire frame for the PSF. I could make some tweaks here and there such as matching the wire frame and heat map color bars but this is already more than enough to visualize a single data point, I need to start working my way up to 10 million.&lt;/p&gt;</summary><category term="wfc3"></category><category term="psf"></category><category term="uvis"></category><category term="plots"></category><category term="code"></category><category term="python"></category></entry><entry><title>The Moving Target Pipeline</title><link href="http://acviana.github.io/posts/2013/mtpipeline-ddrf/" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-18:posts/2013/mtpipeline-ddrf/</id><summary type="html">&lt;p&gt;A few weeks ago I was awarded an research grant to continue working on a prototype software pipeline for HST moving target (solar system) observations. The grant came from an internal source called the Director's Discretionary Research Fund (DDRF). My project, called the Moving Target Pipeline, was fully funded at $21,000 and allows me to buy back 25% of my time for one year to work on the project. Here is the proposal abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"We propose a moving target pipeline for the WFC3 and ACS instruments based our existing WFPC2 software to produce properly drizzled FITS images, dynamically scaled preview images, and predicted ephemeris positions. Such a pipeline is relevant to ongoing HST scientific observations, the Hubble Legacy Archive (HLA), and serves to lay the design groundwork for JWST’s moving target processing. We request funds to support a senior RIA for our software development activities. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Continuing from the proposal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Our WFPC2 pipeline addresses the 4 main issues that impede performing Solar System astronomy with HST archival data: (1) identifying cosmic rays, (2) drizzling, (3) scaled preview images, and (4) identifying incidental ephemeris observations."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This image gives an attractive visual of what we can already accomplish for WFPC2 data and will expand to the WFC3 and ACS cameras:&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/mtpipeline-mars-before-after.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can find the full proposal &lt;a href="https://www.dropbox.com/s/04m5rboqkkmzuvm/2013_Fall_DDRF_Proposal_No_Recs.pdf"&gt;here&lt;/a&gt;. Our project will be open source and available on GitHub. It will be an extension of our existing work on a citizen science project for WFPC2 which you can browse &lt;a href="" title="https://github.com/STScI-Citizen-Science/MTPipeline"&gt;here&lt;/a&gt;. This builds off a number of other grants and &lt;a href="http://archive.stsci.edu/prepds/planetpipeline/index.html"&gt;existing work&lt;/a&gt; in this area &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I hope that this phase of the project will be useful for planetary scientists using HST.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Full disclosure, I misspelled "activities" in the actual abstract. &lt;em&gt;facepalm&lt;/em&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Humblebrag / scavenger hunt, spot the astronaut co-investigator in the parent proposal :-)&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="mtpipeline"></category><category term="milestones"></category><category term="wfc3"></category><category term="acs"></category><category term="hst"></category><category term="jwst"></category><category term="wfpc2"></category></entry><entry><title>The Trouble with Tech Blogs</title><link href="http://acviana.github.io/posts/2013/the-trouble-with-tech-blogs/" rel="alternate"></link><updated>2013-11-17T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-17:posts/2013/the-trouble-with-tech-blogs/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;the trouble with poetry is&lt;br /&gt;
that it encourages the writing of more poetry&lt;br /&gt;
 - Billy Collins, &lt;a href="http://www.edutopia.org/trouble-poetry"&gt;The Trouble with Poetry&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To paraphrase one of my favorite poets, the trouble with tech blogs is that they encourage the writing of more tech blogs. The Internet probably doesn't need another tech blog but I think this will be a fun way for me to both share and keep track of what I'm working on. Hopefully, some people will at least find it entertaining if not helpful.&lt;/p&gt;
&lt;p&gt;I tried to start this blog over a year ago with Octopress. I'd never worked with ruby before but I immediately feel in love with the idea of static HTML generated from Markdown. It seemed so elegant yet customizable, definitely a hacker's blogging platform. Of course I almost immediately broke the deploy step to GitHub and got pulled away to other projects. Then I stumbled across Pelican earlier this year, which is the same idea as Octopress but in Python! After several false starts I now finally have a working blog again! &lt;/p&gt;
&lt;p&gt;And so another tech blog begins!&lt;/p&gt;</summary><category term="pelican"></category></entry></feed>
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>The Other Side of the Screen</title><link href="http://acviana.github.io/" rel="alternate"></link><link href="http://acviana.github.io/feeds/work.atom.xml" rel="self"></link><id>http://acviana.github.io/</id><updated>2013-11-23T00:00:00-05:00</updated><entry><title>A Basic Automation Setup for Astronomy: Part 1</title><link href="http://acviana.github.io/posts/2013/11/23/a-basic-automation-setup/" rel="alternate"></link><updated>2013-11-23T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-23:posts/2013/11/23/a-basic-automation-setup/</id><summary type="html">&lt;p&gt;For one of my projects at work I engineered an automation platform for one of our instrument teams. This platform allows us to automatically execute 20+ daily scripts, written in a variety of programming languages, as data is coming down from the telescope. All the scripts for our team, from the downloading the data, copying and indexing the data in an SQL database, running in-house scripts, and system self-diagnostics run on the same automation platform. Adding a script to this platform requires as little as 4 lines of code. Our codebase is updated with hourly builds from our team of 6 developers and all execution and maintenance is performed via a service account on a Linux Red Hat virtual machine.&lt;/p&gt;
&lt;p&gt;This is going to be a series of posts where I'm going to cover all the odds and ends I had to stick together to build this system. This is far from a generalized solution but hopefully you can learn from my mistakes and build something to suit your own needs faster and better than I did.&lt;/p&gt;
&lt;p&gt;As an aside, this is what I consider to be the DevOps side of my job. It's only in the last year that this has become part of my work and it's only now that I'm starting to identify this as a valuable skill in response to a hard problem. Previously, I was just embarrassed I kept breaking things. But looking back on it, automating this system in this way is one of the hardest things I've done in my job. I'm fortunate I have a team that didn't tell me to stop wasting my time and do it the old way by running everything by hand. And now that it's up and running I haven't had to fix it in weeks.&lt;/p&gt;
&lt;p&gt;In this first post we'll just cover combining the automated execution solution (cron) with the environment configuration solution (Ureka).&lt;/p&gt;
&lt;h3&gt;Cron: Running Your Code&lt;/h3&gt;
&lt;p&gt;At the heart of our system, like many automation solutions, is the Unix job scheduler &lt;a href="http://en.wikipedia.org/wiki/Cron"&gt;cron&lt;/a&gt;. There are other applications our team considered using to fill this role such as &lt;a href="http://research.cs.wisc.edu/htcondor/"&gt;Condor&lt;/a&gt; a distributed computing platform, &lt;a href="http://jenkins-ci.org/"&gt;Jenkins CI&lt;/a&gt; a java-based web frontend for continuous integration, &lt;a href="http://en.wikipedia.org/wiki/Launchd"&gt;launchd&lt;/a&gt; an OSX job scheduler, and even &lt;a href="http://www.celeryproject.org/"&gt;Celery&lt;/a&gt; a distributed job queue. In the end we chose cron because, once we got it working, it was the most direct and simple solution for our architecture. However, as you'll see later, that simplicity made it incredibly difficult to use with IRAF/PyRAF. But first let's start with some cron basics.&lt;/p&gt;
&lt;p&gt;If you look at some cron tutorials you'll see that cron jobs are scheduled with a syntax like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will execute &lt;code&gt;my_script.py&lt;/code&gt; every day at 11 am. This is nothing you can't find in any cron tutorial but here are some tricks I found useful that I had to dig around for a little bit. You can also run multiple scripts sequentially on one line by separating them with a semicolon (&lt;code&gt;;&lt;/code&gt;) like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Each script will run once after the preceding script finishes regardless of the preceding script's exit status. Alternatively, you can make the execution of the second script dependent on the successful completion of the first script with a double ampersand (&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;) like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now cron is likely going to try to be helpful by emailing you any outputs from your code. The recipient of this email can be defined by setting the &lt;code&gt;MAILTO&lt;/code&gt; variable before the job definitions like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;MAILTO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;my_team_list&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;my_institution&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edu&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also define any other variables or alias you want in this same manner. But let's say that you only want to hear from cron when something breaks. You can do this by redirecting &lt;code&gt;STDOUT&lt;/code&gt; just as you would from the command line:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;MAILTO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;my_team_list&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;my_institution&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;edu&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;my_first_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now you will only get an email when something gets passed to &lt;code&gt;STDERR&lt;/code&gt;. For our setup, this is all the cron syntax we needed to understand. Now onto setting up you environment.&lt;/p&gt;
&lt;h3&gt;Ureka: Setting Up Your Environment&lt;/h3&gt;
&lt;p&gt;Right now you might be thinking, &lt;em&gt;"My environment is already set up! Right?"&lt;/em&gt;. This is when using cron starts to become a little non-trivial; cron does not know about your &lt;a href="http://stackoverflow.com/questions/2229825/where-can-i-set-environment-variables-that-crontab-will-use"&gt;enviorment variables&lt;/a&gt;, like &lt;em&gt;any&lt;/em&gt; of them. In a lot of applications this is not a big deal, you can just define some environment variables just like I defined &lt;code&gt;MAILTO&lt;/code&gt; above, and you're set. &lt;/p&gt;
&lt;p&gt;But, if you're in astronomy one of your default software tools is likely IRAF/PyRAF. This takes installing software and declaring environment variables to an entirely new level of difficulty. I spent &lt;em&gt;weeks&lt;/em&gt; working on the problem of getting cron to run in an IRAF/PyRAF compatible environment without any success. I tried half a dozen different approaches and talked to several people, all of who confessed to giving up due to the same complication. In the end, I partnered with one of our best IT people and we came up with a solution. The first step of that solution is to use Ureka. &lt;/p&gt;
&lt;p&gt;&lt;a href="http://ssb.stsci.edu/ureka/"&gt;Ureka&lt;/a&gt; is a software package developed by STScI and Gemini. From the website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ureka is a collection of useful astronomy software that is generally centered around Python and IRAF. The software provides everything you need to run the data reduction packages provided by STScI and Gemini.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ureka is great, it builds a completely isolated IRAF and Python environment in minutes and loads or unloads the environment with a single command. You can run ds9, IRAF, PyRAF, and Python. Plus Python comes loaded with IPython, the IPython notebook, matplotlib, numpy, scipy, and pandas. If you need more than that you can immediately run &lt;code&gt;pip install&lt;/code&gt; because your paths have already been set up for you. You're on your own for IDL though.&lt;/p&gt;
&lt;p&gt;Whether you're like me and work on an institute machine with pre-built libraries or if you're running everything on your own machine and have root, Ureka is worth looking into because it &lt;em&gt;just works&lt;/em&gt;. I spent a lot of time learning to use package managers, building from source into different prefixes, virtualenv, and the ins and outs of pip, but when I got a new virtual machine last month I used Ureka and literally set up everything I needed in 3 commands. I was sold.&lt;/p&gt;
&lt;p&gt;So now we have our automation tool, cron, and our environment setup with Ureka. Now it's time to combine them.&lt;/p&gt;
&lt;h3&gt;Cron + Ureka: Automatic Environment Setup&lt;/h3&gt;
&lt;p&gt;Like we just saw, you can run more than one script on a single line in cron. You can start the Ureka environment with the command &lt;code&gt;ur_setup&lt;/code&gt; and exit with &lt;code&gt;ur_forget&lt;/code&gt;. So I &lt;em&gt;thought&lt;/em&gt; the following command would have been enough to run our scripts:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;ur_setup&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But it doesn't work. Somehow this does not run &lt;code&gt;my_second_script.py&lt;/code&gt; using the environment set up by &lt;code&gt;ur_setup&lt;/code&gt;, my guess is that each script is launched in an independent shell that doesn't propagate variables back to the parent cron environment. This independence is generally a desirable feature so that makes sense, though it makes life hard in our case. This is where everyone I talked to crashed and burned when trying to use cron to automate astronomy software, whether they were using Ureka or not. But eventually one of our IT specialists worked out a wrapper script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/tcsh&lt;/span&gt;
ur_setup
&lt;span class="s2"&gt;&amp;quot;$*&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's non-intuitive at first but what it does it runs &lt;code&gt;ur_setup&lt;/code&gt; and then takes a script name as a command line argument and runs that script. Because this is all done in the same shell session the script is launched in the Ureka environment - &lt;em&gt;finally&lt;/em&gt;. I can't tell you how happy I was to finally get this to work. The execution looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="mo"&gt;00&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;cron_setup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt; &lt;span class="n"&gt;my_second_script&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;null&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Done, Right?&lt;/h3&gt;
&lt;p&gt;That was a bit of a long post, and you might be tempted to call it quits and just run with this setup, but I would encourage you not to. We still have to talk about a deployment solution for your code using your version control system (because your code is version controlled right?), using Python to wrap code written in other languages, using the Python logging module to generate logs. Doesn't that sound nice? I'll put the link to all that right [here] once it's ready.&lt;/p&gt;</summary><category term="code"></category><category term="devops"></category></entry><entry><title>The Data are Inconclusive</title><link href="http://acviana.github.io/posts/2013/11/21/the-data-are-inconclusive/" rel="alternate"></link><updated>2013-11-21T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-21:posts/2013/11/21/the-data-are-inconclusive/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;"Give me a point and I can draw a line. Give me two points and I can draw a curve. That's astronomy." - Anonymous Professor.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ran the full pipeline the PSF data for the first time. The data are inconclusive.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/inconclusive-data.png" /&gt;&lt;/p&gt;
&lt;p&gt;Haha, oh error bars. Who hasn't made a plot just like this before? &lt;/p&gt;</summary><category term="psf"></category></entry><entry><title>The First Thousand PSFs</title><link href="http://acviana.github.io/posts/2013/11/20/the-first-thousand-psfs/" rel="alternate"></link><updated>2013-11-20T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-20:posts/2013/11/20/the-first-thousand-psfs/</id><summary type="html">&lt;p&gt;In my last post on my PSF Project I characterized the PSF shape by fitting a 1-D Gaussian to the a row and column slice through the central pixel. In this post I start to think about how to characterize entire images with thousands of stars.&lt;/p&gt;
&lt;h3&gt;Adding Some Zeros&lt;/h3&gt;
&lt;p&gt;Many applications for the PSF database involve looking at PSF changes over a time series. One way to do this is to move from characterizing individual PSFs to characterizing the PSFs in an entire image and seeing how that changes over time. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; In other words, we need to add some zeros to our lone star and start working our way towards our final dataset of 10 million. I decided to do this by digging into the first stellar field I could find. This happened to be &lt;code&gt;iabj01a2q_flt.fits&lt;/code&gt; an image of &lt;a href="http://en.wikipedia.org/wiki/47_Tucanae"&gt;NGC104&lt;/a&gt; which adds 3 more zeros to our star total, bringing it to roughly 1,500 stars. Here is the image, it's actually quite nice (sorry for the large file):&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/Visit01-iabj01a2q_flt.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;In case you want to play along at home, this image is in the public domain and can be found &lt;a href="http://archive.stsci.edu/cgi-bin/mastpreview?mission=hst&amp;amp;dataid=IABJ01A2Q"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;h3&gt;Plotting the PSF Fits&lt;/h3&gt;
&lt;p&gt;So I went ahead and fitted a Gaussian in both the row and column directions for all the stars in that image. Then I studied the distribution by plotting the fit parameters against each other in each slice.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/image_variable_matrix.png" /&gt;&lt;/p&gt;
&lt;p&gt;First of all, in hindsight what I wanted was a &lt;a href="https://www.google.com/webhp#q=scatter%20plot%20matrix"&gt;scatter plot matrix&lt;/a&gt; but this is exploratory work so I can go back and make that plot in the future.&lt;/p&gt;
&lt;p&gt;In terms of the actual data, we don't see anything noticeably different between the row and column slices, which is expected at this point, though there there may be directionally-dependent instrumental effects, such as the charge transfer efficiency, which may come into play later. Looking at the individual fit parameters there's not much going on with the amplitude but things get interesting when we plot the standard deviation against the mean (&lt;code&gt;mu&lt;/code&gt;). However, the correlation we're seeing in the plot is actually a sampling effect. &lt;/p&gt;
&lt;h3&gt;Interpreting the Results&lt;/h3&gt;
&lt;p&gt;Let's start by explaining what &lt;code&gt;sigma&lt;/code&gt; and &lt;code&gt;mu&lt;/code&gt; mean in this context (it might be helpful to refer to my &lt;a href="http://acviana.github.io/posts/2013/11/18/counting-to-10-million-stars/"&gt;last post&lt;/a&gt;). First of all, &lt;code&gt;mu&lt;/code&gt;, the mean of the Gaussian fit is almost always between 4.5 and 5.5. This is by design because the algorithm that centers the PSF cutouts does a good job of picking the brightest pixel. &lt;code&gt;sigma&lt;/code&gt; then is a measure of the width of the PSF. &lt;/p&gt;
&lt;p&gt;The actual energy distribution of a star is a continuous distribution. However, detectors take discrete samples from this distribution, pretty much literally making a histogram. If you've played around with histograms much you might see where this is going. If a star happens to land exactly in the middle of a pixel (&lt;code&gt;mu&lt;/code&gt; = 5) most of the light from the PSF will land in that pixel. This will result in a narrow &lt;code&gt;sigma&lt;/code&gt;. But is the &lt;em&gt;same&lt;/em&gt; PSF lands right in the middle of two pixels (equidistant from their centers) then the same amount of flux is split between those two pixels. The total amount of flux is still the same, but the distribution is different. This distribution is less peaked, which is to say wider and with a larger &lt;code&gt;sigma&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;I think this is supported by the fact that as you move away from the middle of the central pixel (&lt;code&gt;mu&lt;/code&gt; = 5) the distribution of &lt;code&gt;sigma&lt;/code&gt; for a given mean moves up (gets wider) in an absolute sense, but not in a relative sense. Put another way, the width of you PSF increases the further the peak is from the central pixel, but the difference between a peaked and broad PSF at any given mean is about the same.&lt;/p&gt;
&lt;h3&gt;What's Next?&lt;/h3&gt;
&lt;p&gt;The next step is pretty clear, we need to use this distribution of parameters to characterize the "average" PSF shape in each image and plot that as a time series. This will almost certainly yield nothing but noise, but I'm confident that as we tease the data out such as separating each filter or different parts of the detector we'll start to see some real trends.&lt;/p&gt;
&lt;p&gt;But, this sampling effect is bothering me. If we just take a mean and standard distribution of all the &lt;code&gt;sigma&lt;/code&gt; parameters in each image those results are going to be heavily influenced by the sampling effect (I'm deliberately trying to avoid saying the &lt;code&gt;sigma&lt;/code&gt; of the &lt;code&gt;sigma&lt;/code&gt;s.). However, after looking at a sample set of plots I think this is likely characteristic of all our data. Consistency will have to suffice for now because as you'll see in my next post there are more pressing problems as we start to add zeros to our star count. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Most astronomers talk about PSF widths in terms of the full width at half maximum (&lt;a href="http://en.wikipedia.org/wiki/Full_width_at_half_maximum"&gt;FWHM&lt;/a&gt;). I'm using the standard deviation (sigma) in my work but they only differ by a coefficient; &lt;code&gt;FWHM = sigma x 2 x (2 x ln(s)) ^ (1/2)&lt;/code&gt;. Sorry about the lack of nice math symbols, I haven't played with that plugin yet.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="wfc3"></category><category term="psf"></category><category term="uvis"></category><category term="plots"></category></entry><entry><title>Counting to 10 Million Stars</title><link href="http://acviana.github.io/posts/2013/11/18/counting-to-10-million-stars/" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-18:posts/2013/11/18/counting-to-10-million-stars/</id><summary type="html">&lt;p&gt;I've started a new project working with 10 million stellar PSFs. In my first few steps in the project I performed some model fitting and made a pretty visualization of the individual data points.&lt;/p&gt;
&lt;h3&gt;My New (Little) Big Data Project&lt;/h3&gt;
&lt;p&gt;I am starting a new project that I'm pretty excited, it's one of the reasons I decided to start this blog. about because it is pushing me more in the direction of "Big Data". Lots of people throw the term big data around with different meanings. Personally, I consider something to be Big Data when the complexity of the task is dominated by complications from the size of the data. The "task" could be anything related to the data including storage, computation, or visualization. Specifically, this project is going to push the computation and database aspects of my work into the Big Data zone.&lt;/p&gt;
&lt;p&gt;The dataset for this project is 10 million stellar &lt;a href="http://en.wikipedia.org/wiki/Point_spread_function"&gt;PSFs&lt;/a&gt; observations taken with the HST WFC3 UVIS instrument. These PSF were data mined from the total on-orbit data set of roughly 35 thousand WFC3 UVIS observations using a colleague's specialized FORTRAN code which extracted a 11x11 array centered on each PSF. This is an especially powerful method of constructing our dataset because it allows us to use any incidental PSFs observations when the target was not a star or stellar field.&lt;/p&gt;
&lt;h3&gt;Fitting 1-D Gaussian Distributions&lt;/h3&gt;
&lt;p&gt;After some initial work I was able to create a reader that takes the outputs text files from my colleague's code and transforms it into a numpy array. Next, we decided we wanted to start by characterizing the PSFs with two 1-D Gaussian fits through the center pixel, one in the row direction and another in the column.&lt;/p&gt;
&lt;p&gt;First of all, I was &lt;em&gt;shocked&lt;/em&gt; to learn, after an hour of googling and popping my head into people's offices, that the definition of a Gaussian distribution isn't tucked away somewhere in NumPy or SciPy. Thinking about it, it &lt;em&gt;guess&lt;/em&gt; makes sense because it's not clear what format your inputs and outputs should be, but I'm still a little surprised that all the tutorials I found on this subject began with defining the Gaussian distribution. Anyway, once I got past that the rest wasn't too hard. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy.optimize&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;curve_fit&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Definintion of the Guassian function.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_gaussian_dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Use curve fit to return a dictionary with all the model &lt;/span&gt;
&lt;span class="sd"&gt;    information.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;p0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;where&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;coeff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;var_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;curve_fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coeff&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;amplitude&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;mu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sigma&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;var_matrix&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;var_matrix&lt;/span&gt;
    &lt;span class="n"&gt;output_dict&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;model_data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gaussian&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;resample_range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mu&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sigma&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output_dict&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I use scipy's impressive &lt;code&gt;curve_fit&lt;/code&gt; function to perform the model fitting. The last argument &lt;code&gt;curve_fit&lt;/code&gt; takes is &lt;code&gt;p0&lt;/code&gt;, the initial guess for the fitting parameters. Fortunately, our data is very well behaved so we can easily do a good job guessing the initial parameters from the input data. Because I like to make my functions as general as possible I return all the possible information from the fit in a dictionary. For example, in the future I'll probably want to dig into the &lt;a href="http://en.wikipedia.org/wiki/Covariance_matrix"&gt;covariance matrix&lt;/a&gt; that the &lt;code&gt;curve_fit&lt;/code&gt; returns to calculate a goodness of fit estimator and I'll be able to do that with the same function. &lt;/p&gt;
&lt;h3&gt;Eye Candy&lt;/h3&gt;
&lt;p&gt;Finally, all this is all visualized in the 4-panel figure below.&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/psf-4-panel-view.png" /&gt;&lt;/p&gt;
&lt;p&gt;The bottom row contains the row and column slices and the Gaussian fits with the model parameters printed in the upper corners. The upper row contains a heat map, and just for fun, a 3D wire frame for the PSF. I could make some tweaks here and there such as matching the wire frame and heat map color bars but this is already more than enough to visualize a single data point, I need to start working my way up to 10 million.&lt;/p&gt;</summary><category term="wfc3"></category><category term="psf"></category><category term="uvis"></category><category term="plots"></category><category term="code"></category><category term="python"></category></entry><entry><title>The Moving Target Pipeline</title><link href="http://acviana.github.io/posts/2013/11/18/mtpipeline-ddrf/" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-18:posts/2013/11/18/mtpipeline-ddrf/</id><summary type="html">&lt;p&gt;A few weeks ago I was awarded an research grant to continue working on a prototype software pipeline for HST moving target (solar system) observations. The grant came from an internal source called the Director's Discretionary Research Fund (DDRF). My project, called the Moving Target Pipeline, was fully funded at $21,000 and allows me to buy back 25% of my time for one year to work on the project. Here is the proposal abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"We propose a moving target pipeline for the WFC3 and ACS instruments based our existing WFPC2 software to produce properly drizzled FITS images, dynamically scaled preview images, and predicted ephemeris positions. Such a pipeline is relevant to ongoing HST scientific observations, the Hubble Legacy Archive (HLA), and serves to lay the design groundwork for JWST’s moving target processing. We request funds to support a senior RIA for our software development activities. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Continuing from the proposal:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Our WFPC2 pipeline addresses the 4 main issues that impede performing Solar System astronomy with HST archival data: (1) identifying cosmic rays, (2) drizzling, (3) scaled preview images, and (4) identifying incidental ephemeris observations."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This image gives an attractive visual of what we can already accomplish for WFPC2 data and will expand to the WFC3 and ACS cameras:&lt;/p&gt;
&lt;p&gt;&lt;img style="width: 800px; max-width: 100%; height: auto;" alt="Oops, something broke." src="/images/mtpipeline-mars-before-after.png" /&gt;&lt;/p&gt;
&lt;p&gt;You can find the full proposal &lt;a href="https://www.dropbox.com/s/04m5rboqkkmzuvm/2013_Fall_DDRF_Proposal_No_Recs.pdf"&gt;here&lt;/a&gt;. Our project will be open source and available on GitHub. It will be an extension of our existing work on a citizen science project for WFPC2 which you can browse &lt;a href="" title="https://github.com/STScI-Citizen-Science/MTPipeline"&gt;here&lt;/a&gt;. This builds off a number of other grants and &lt;a href="http://archive.stsci.edu/prepds/planetpipeline/index.html"&gt;existing work&lt;/a&gt; in this area &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I hope that this phase of the project will be useful for planetary scientists using HST.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Full disclosure, I misspelled "activities" in the actual abstract. &lt;em&gt;facepalm&lt;/em&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Humblebrag / scavenger hunt, spot the astronaut co-investigator in the parent proposal :-)&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="mtpipeline"></category><category term="milestones"></category><category term="wfc3"></category><category term="acs"></category><category term="hst"></category><category term="jwst"></category><category term="wfpc2"></category></entry><entry><title>The Trouble with Tech Blogs</title><link href="http://acviana.github.io/posts/2013/11/17/the-trouble-with-tech-blogs/" rel="alternate"></link><updated>2013-11-17T00:00:00-05:00</updated><author><name>Alex C. Viana</name></author><id>tag:acviana.github.io,2013-11-17:posts/2013/11/17/the-trouble-with-tech-blogs/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;the trouble with poetry is&lt;br /&gt;
that it encourages the writing of more poetry&lt;br /&gt;
 - Billy Collins, &lt;a href="http://www.edutopia.org/trouble-poetry"&gt;The Trouble with Poetry&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To paraphrase one of my favorite poets, the trouble with tech blogs is that they encourage the writing of more tech blogs. The Internet probably doesn't need another tech blog but I think this will be a fun way for me to both share and keep track of what I'm working on. Hopefully, some people will at least find it entertaining if not helpful.&lt;/p&gt;
&lt;p&gt;I tried to start this blog over a year ago with Octopress. I'd never worked with ruby before but I immediately feel in love with the idea of static HTML generated from Markdown. It seemed so elegant yet customizable, definitely a hacker's blogging platform. Of course I almost immediately broke the deploy step to GitHub and got pulled away to other projects. Then I stumbled across Pelican earlier this year, which is the same idea as Octopress but in Python! After several false starts I now finally have a working blog again! &lt;/p&gt;
&lt;p&gt;And so another tech blog begins!&lt;/p&gt;</summary><category term="pelican"></category></entry></feed>